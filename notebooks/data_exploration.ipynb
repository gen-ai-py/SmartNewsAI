{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart News AI - Data Exploration and Analysis\n",
    "\n",
    "This notebook provides an interactive analysis of the Smart News AI system, including:\n",
    "- Dataset exploration\n",
    "- Classification model training and evaluation\n",
    "- Recommendation system analysis\n",
    "- Visualization of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Import custom modules\n",
    "from data_generator import create_sample_data\n",
    "from data_preprocessing import FeatureExtractor, create_train_test_split\n",
    "from news_classifier import NewsClassifier, ModelComparison\n",
    "from recommendation_engine import HybridRecommender, generate_sample_interactions\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Generation and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data if not exists\n",
    "data_path = '../data'\n",
    "articles_path = os.path.join(data_path, 'news_articles.csv')\n",
    "\n",
    "if not os.path.exists(articles_path):\n",
    "    print(\"Generating sample data...\")\n",
    "    create_sample_data(data_path)\n",
    "\n",
    "# Load datasets\n",
    "articles_df = pd.read_csv(articles_path)\n",
    "interactions_df = pd.read_csv(os.path.join(data_path, 'user_interactions.csv'))\n",
    "\n",
    "print(f\"Loaded {len(articles_df)} articles and {len(interactions_df)} interactions\")\n",
    "print(f\"Categories: {', '.join(articles_df['category'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset information\n",
    "print(\"=== Articles Dataset ===\")\n",
    "print(articles_df.info())\n",
    "print(\"\\n=== Sample Articles ===\")\n",
    "print(articles_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "category_counts = articles_df['category'].value_counts()\n",
    "plt.pie(category_counts.values, labels=category_counts.index, autopct='%1.1f%%')\n",
    "plt.title('Article Category Distribution')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "category_counts.plot(kind='bar')\n",
    "plt.title('Articles per Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Category Statistics:\")\n",
    "print(category_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content length analysis\n",
    "articles_df['content_length'] = articles_df['content'].str.len()\n",
    "articles_df['title_length'] = articles_df['title'].str.len()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(articles_df['content_length'], bins=30, alpha=0.7)\n",
    "plt.title('Content Length Distribution')\n",
    "plt.xlabel('Characters')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(articles_df['title_length'], bins=30, alpha=0.7, color='orange')\n",
    "plt.title('Title Length Distribution')\n",
    "plt.xlabel('Characters')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(data=articles_df, x='category', y='content_length')\n",
    "plt.title('Content Length by Category')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Content Length Statistics:\")\n",
    "print(articles_df['content_length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User interaction analysis\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "interactions_df['rating'].hist(bins=5, alpha=0.7, color='green')\n",
    "plt.title('Rating Distribution')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "rating_by_category = interactions_df.groupby('category')['rating'].mean().sort_values()\n",
    "rating_by_category.plot(kind='bar', color='skyblue')\n",
    "plt.title('Average Rating by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "user_activity = interactions_df['user_id'].value_counts()\n",
    "plt.hist(user_activity, bins=20, alpha=0.7, color='purple')\n",
    "plt.title('User Activity Distribution')\n",
    "plt.xlabel('Number of Interactions')\n",
    "plt.ylabel('Number of Users')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Interaction Statistics:\")\n",
    "print(f\"Average rating: {interactions_df['rating'].mean():.2f}\")\n",
    "print(f\"Total unique users: {interactions_df['user_id'].nunique()}\")\n",
    "print(f\"Average interactions per user: {len(interactions_df) / interactions_df['user_id'].nunique():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Analysis and Word Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word clouds for different categories\n",
    "categories = articles_df['category'].unique()[:4]  # Show first 4 categories\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    if i >= 4:\n",
    "        break\n",
    "        \n",
    "    category_text = ' '.join(articles_df[articles_df['category'] == category]['content'])\n",
    "    \n",
    "    try:\n",
    "        wordcloud = WordCloud(\n",
    "            width=400, \n",
    "            height=300, \n",
    "            background_color='white',\n",
    "            max_words=50,\n",
    "            colormap='viridis'\n",
    "        ).generate(category_text)\n",
    "        \n",
    "        axes[i].imshow(wordcloud, interpolation='bilinear')\n",
    "        axes[i].set_title(f'{category.title()} Category', fontsize=14)\n",
    "        axes[i].axis('off')\n",
    "    except Exception as e:\n",
    "        axes[i].text(0.5, 0.5, f'WordCloud error for {category}', \n",
    "                    ha='center', va='center', transform=axes[i].transAxes)\n",
    "        axes[i].set_title(f'{category.title()} Category', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classification Model Training and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for classification\n",
    "print(\"Preparing data for classification...\")\n",
    "\n",
    "feature_extractor = FeatureExtractor(max_features=3000)\n",
    "X = feature_extractor.fit_transform_text(articles_df['content'].tolist())\n",
    "y = feature_extractor.fit_transform_labels(articles_df['category'].tolist())\n",
    "\n",
    "X_train, X_test, y_train, y_test = create_train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare multiple models\n",
    "print(\"Comparing classification models...\")\n",
    "\n",
    "model_types = ['random_forest', 'logistic_regression', 'naive_bayes']\n",
    "comparison = ModelComparison(model_types)\n",
    "results, best_model = comparison.compare_models(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Create comparison visualization\n",
    "results_df = comparison.get_results_dataframe()\n",
    "print(\"\\nModel Comparison Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "\n",
    "for i, metric in enumerate(metrics, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    results_df[metric].plot(kind='bar')\n",
    "    plt.title(f'{metric.title()} Comparison')\n",
    "    plt.ylabel(metric.title())\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBest performing model: {best_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis of the best model\n",
    "best_classifier = comparison.models[best_model]\n",
    "detailed_metrics = best_classifier.evaluate(X_test, y_test, detailed=True)\n",
    "\n",
    "print(f\"Detailed Analysis - {best_model}\")\n",
    "print(\"=\" * 40)\n",
    "print(detailed_metrics['classification_report'])\n",
    "\n",
    "# Confusion Matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = detailed_metrics['confusion_matrix']\n",
    "categories = feature_extractor.label_encoder.classes_\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=categories, yticklabels=categories)\n",
    "plt.title(f'Confusion Matrix - {best_model}')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "feature_names = feature_extractor.get_feature_names()\n",
    "if len(feature_names) > 0 and hasattr(best_classifier, 'feature_importance'):\n",
    "    top_features = best_classifier.get_top_features(feature_names, n_features=20)\n",
    "    \n",
    "    # Plot top features\n",
    "    features, importances = zip(*top_features)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(range(len(features)), importances)\n",
    "    plt.yticks(range(len(features)), features)\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title(f'Top 20 Important Features - {best_model}')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Top 10 Important Features:\")\n",
    "    for feature, importance in top_features[:10]:\n",
    "        print(f\"{feature}: {importance:.4f}\")\n",
    "else:\n",
    "    print(\"Feature importance not available for this model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Recommendation System Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train recommendation system\n",
    "print(\"Training hybrid recommendation system...\")\n",
    "\n",
    "recommender = HybridRecommender(content_weight=0.6, collaborative_weight=0.4)\n",
    "recommender.fit(articles_df, interactions_df)\n",
    "\n",
    "print(\"Recommendation system trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze user preferences\n",
    "sample_users = interactions_df['user_id'].value_counts().head(5).index.tolist()\n",
    "\n",
    "print(\"User Preference Analysis\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for user_id in sample_users:\n",
    "    user_profile = recommender.get_user_profile(user_id)\n",
    "    user_interactions = interactions_df[interactions_df['user_id'] == user_id]\n",
    "    \n",
    "    print(f\"\\nUser: {user_id}\")\n",
    "    print(f\"Total interactions: {len(user_interactions)}\")\n",
    "    print(f\"Average rating: {user_interactions['rating'].mean():.2f}\")\n",
    "    \n",
    "    # Category preferences\n",
    "    category_ratings = user_interactions.groupby('category')['rating'].agg(['count', 'mean'])\n",
    "    print(f\"Category preferences:\")\n",
    "    for category, stats in category_ratings.iterrows():\n",
    "        print(f\"  {category}: {stats['count']} articles, avg rating {stats['mean']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo recommendation for sample users\n",
    "demo_user = sample_users[0]\n",
    "\n",
    "print(f\"Generating recommendations for user: {demo_user}\")\n",
    "\n",
    "recommendations = recommender.get_recommendations(demo_user, n_recommendations=5)\n",
    "\n",
    "print(f\"\\nTop 5 Recommendations for {demo_user}:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. {rec['title']} ({rec['category']})\")\n",
    "    print(f\"   Hybrid Score: {rec['hybrid_score']:.3f}\")\n",
    "    print(f\"   Content Score: {rec['content_score']:.3f}\")\n",
    "    print(f\"   Collaborative Score: {rec['collaborative_score']:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive performance dashboard\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Category distribution\n",
    "axes[0, 0].pie(category_counts.values, labels=category_counts.index, autopct='%1.1f%%')\n",
    "axes[0, 0].set_title('Article Category Distribution')\n",
    "\n",
    "# 2. Model performance comparison\n",
    "results_df['accuracy'].plot(kind='bar', ax=axes[0, 1], color='skyblue')\n",
    "axes[0, 1].set_title('Model Accuracy Comparison')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Content length by category\n",
    "category_length = articles_df.groupby('category')['content_length'].mean()\n",
    "category_length.plot(kind='bar', ax=axes[0, 2], color='lightgreen')\n",
    "axes[0, 2].set_title('Average Content Length by Category')\n",
    "axes[0, 2].set_ylabel('Characters')\n",
    "axes[0, 2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Rating distribution\n",
    "interactions_df['rating'].hist(bins=5, ax=axes[1, 0], alpha=0.7, color='orange')\n",
    "axes[1, 0].set_title('User Rating Distribution')\n",
    "axes[1, 0].set_xlabel('Rating')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# 5. User activity\n",
    "user_activity.head(20).plot(kind='bar', ax=axes[1, 1], color='purple')\n",
    "axes[1, 1].set_title('Top 20 Most Active Users')\n",
    "axes[1, 1].set_ylabel('Interactions')\n",
    "axes[1, 1].tick_params(axis='x', rotation=90, labelsize=8)\n",
    "\n",
    "# 6. Average rating by category\n",
    "rating_by_category.plot(kind='bar', ax=axes[1, 2], color='coral')\n",
    "axes[1, 2].set_title('Average Rating by Category')\n",
    "axes[1, 2].set_ylabel('Average Rating')\n",
    "axes[1, 2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Smart News AI - Analysis Summary\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"ðŸ“Š Dataset Statistics:\")\n",
    "print(f\"   â€¢ Total articles: {len(articles_df):,}\")\n",
    "print(f\"   â€¢ Categories: {len(articles_df['category'].unique())}\")\n",
    "print(f\"   â€¢ User interactions: {len(interactions_df):,}\")\n",
    "print(f\"   â€¢ Unique users: {interactions_df['user_id'].nunique():,}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Classification Performance:\")\n",
    "print(f\"   â€¢ Best model: {best_model}\")\n",
    "print(f\"   â€¢ Best accuracy: {results_df.loc[best_model, 'accuracy']:.3f}\")\n",
    "print(f\"   â€¢ Best F1-score: {results_df.loc[best_model, 'f1_score']:.3f}\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ Key Insights:\")\n",
    "most_popular = category_counts.index[0]\n",
    "highest_rated = rating_by_category.index[-1]\n",
    "print(f\"   â€¢ Most popular category: {most_popular} ({category_counts.iloc[0]} articles)\")\n",
    "print(f\"   â€¢ Highest rated category: {highest_rated} (avg: {rating_by_category.iloc[-1]:.2f})\")\n",
    "print(f\"   â€¢ Average user engagement: {interactions_df.groupby('user_id').size().mean():.1f} interactions per user\")\n",
    "\n",
    "print(f\"\\nðŸš€ System Capabilities:\")\n",
    "print(f\"   â€¢ Multi-class text classification with {len(feature_extractor.label_encoder.classes_)} categories\")\n",
    "print(f\"   â€¢ Hybrid recommendation system (content + collaborative filtering)\")\n",
    "print(f\"   â€¢ Real-time article classification and personalized recommendations\")\n",
    "print(f\"   â€¢ Interactive CLI interface for easy usage\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Next Steps:\")\n",
    "print(f\"   â€¢ Experiment with deep learning models (BERT, transformers)\")\n",
    "print(f\"   â€¢ Implement online learning for real-time model updates\")\n",
    "print(f\"   â€¢ Add sentiment analysis and topic modeling\")\n",
    "print(f\"   â€¢ Develop web interface for broader accessibility\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}